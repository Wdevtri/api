name: Scrape Data and Push

on:
  schedule:
    - cron: '*/5 * * * *'  # Run every 5 minutes
  workflow_dispatch:       # Manual trigger available

jobs:
  scrape-and-push:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '16'  # Or '18' for newer support

      - name: Install dependencies
        run: npm install

      - name: Install Chromium (for Puppeteer)
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser
        # NOTE: On GitHub runners, 'chromium-browser' is the right package

      - name: Run the scraper and update files
        env:
          PUPPETEER_EXECUTABLE_PATH: "/usr/bin/chromium-browser"
        run: node scraper.js

      - name: Commit and push updated data
        run: |
          git config --global user.email "nikithamorningstar@gmail.com"
          git config --global user.name "Wdevtri"
          git add prematch.json live.json
          git commit -m "Update scraped data" || echo "No changes to commit"
          git push
