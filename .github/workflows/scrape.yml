name: Scrape Data and Push

on:
  schedule:
    - cron: '*/5 * * * *'  # This will run every 5 minutes
  workflow_dispatch:  # Allow for manual triggering as well

jobs:
  scrape-and-push:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '16'  # You can use the Node.js version that works best for you

      - name: Install dependencies
        run: npm install

      - name: Install Google Chrome
        run: |
          sudo apt update
          sudo apt install -y wget gnupg2
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -  # Add the key
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'  # Add repo
          sudo apt update
          sudo apt install -y google-chrome-stable  # Install Chrome

      - name: Run the scraper and update files
        run: |
          # Ensure PUPPETEER_EXECUTABLE_PATH points to the correct Chrome binary
          export PUPPETEER_EXECUTABLE_PATH="/usr/bin/google-chrome-stable"  # Path for installed Chrome
          node scraper.js

  commit-and-push:
    runs-on: ubuntu-latest
    needs: scrape-and-push
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts

      - name: Set up Git configuration
        run: |
          git config --global user.name "Wdevtri"
          git config --global user.email "nikithamorningstar@gmail.com"

      - name: Commit and push changes
        run: |
          git add .
          git commit -m "Update scraped data"
          git push git@github.com:Wdevtri/api.git
